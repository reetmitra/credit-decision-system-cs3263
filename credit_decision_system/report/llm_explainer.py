import json
from typing import Dict, Optional, Union
from dataclasses import dataclass
import hashlib
from datetime import datetime, timedelta

@dataclass
class ExplanationMetrics:
    """Metrics to track explanation quality and performance."""
    generation_time: float
    explanation_length: int
    confidence_score: Optional[float] = None
    feature_importance: Optional[Dict[str, float]] = None

class LLMExplainer:
    """
    Generate human-readable explanations for credit decisions.
    
    This class provides both LLM-based and rule-based explanations. The LLM explanation uses an external
    client (e.g., an LLM API client) to generate explanations from a natural language prompt.
    When the LLM is not available, a deterministic, rule-based explanation is returned to ensure
    consistent interpretability and fairness.
    
    Academic Integration:
    Inspired by recent research in explainable AI, such as "LLMs for Explainable AI: A Comprehensive Survey"
    (Bilal et al., 2025), the prompt for LLM-based explanations now incorporates academic insights. These
    insights emphasize the integration of post-hoc analyses, intrinsic interpretability, and human-centered
    narrative approaches. The explanation is guided to reflect clarity, factual accuracy, logical coherence,
    and robustness, evaluated via measures of comprehensibility, faithfulness, and plausibility.
    """
    
    def __init__(self, use_llm=True, client=None, NLP_AVAILABLE=True, cache_duration_hours=24):
        """
        Initialize the explainer.
        
        Args:
            use_llm (bool): Flag to indicate whether to use an LLM for explanations.
            client: An instance of an LLM API client. Must be provided if use_llm is True.
            NLP_AVAILABLE (bool): Flag to indicate whether necessary NLP libraries are available.
            cache_duration_hours (int): Duration in hours to cache LLM responses.
        """
        self.use_llm = use_llm and NLP_AVAILABLE and client is not None
        self.client = client
        self.cache_duration = timedelta(hours=cache_duration_hours)
        self._response_cache = {}
        self._last_cache_cleanup = datetime.now()
    
    def _validate_inputs(self, applicant_data: Dict, risk_score: float, threshold: float, 
                         context: str, decision: bool) -> None:
        """Validate input parameters for explanation generation."""
        if not isinstance(applicant_data, dict):
            raise ValueError("applicant_data must be a dictionary")
        if not isinstance(risk_score, (int, float)):
            raise ValueError("risk_score must be numeric")
        if not isinstance(threshold, (int, float)):
            raise ValueError("threshold must be numeric")
        if not isinstance(context, str):
            raise ValueError("context must be a string")
        if not isinstance(decision, bool):
            raise ValueError("decision must be a boolean")
        
        # Validate risk score and threshold ranges
        if not 0 <= risk_score <= 1:
            raise ValueError("risk_score must be between 0 and 1")
        if not 0 <= threshold <= 1:
            raise ValueError("threshold must be between 0 and 1")
    
    def _get_cache_key(self, applicant_data: Dict, risk_score: float, threshold: float, 
                       context: str, decision: bool) -> str:
        """Generate a unique cache key for the input parameters."""
        input_str = json.dumps({
            'applicant_data': applicant_data,
            'risk_score': risk_score,
            'threshold': threshold,
            'context': context,
            'decision': decision
        }, sort_keys=True)
        return hashlib.md5(input_str.encode()).hexdigest()
    
    def _cleanup_cache(self) -> None:
        """Remove expired cache entries."""
        current_time = datetime.now()
        if current_time - self._last_cache_cleanup > timedelta(hours=1):
            self._last_cache_cleanup = current_time
            expired_keys = [
                key for key, (_, timestamp) in self._response_cache.items()
                if current_time - timestamp > self.cache_duration
            ]
            for key in expired_keys:
                del self._response_cache[key]
    
    def _get_cached_response(self, cache_key: str) -> Optional[str]:
        """Retrieve cached response if available and not expired."""
        self._cleanup_cache()
        if cache_key in self._response_cache:
            response, timestamp = self._response_cache[cache_key]
            if datetime.now() - timestamp <= self.cache_duration:
                return response
        return None
    
    def _calculate_feature_importance(self, applicant_data: Dict) -> Dict[str, float]:
        """Calculate relative importance of different features."""
        importance = {}
        numeric_values = [abs(value) for value in applicant_data.values() if isinstance(value, (int, float))]
        if not numeric_values:
            return importance
        total = sum(numeric_values)
        for key, value in applicant_data.items():
            if isinstance(value, (int, float)):
                importance[key] = abs(value) / total
        return importance
    
    def generate_explanation(self, applicant_data: Dict, risk_score: float, threshold: float, 
                             context: str, decision: bool) -> Dict[str, Union[str, ExplanationMetrics]]:
        """
        Generate an explanation for a credit decision.
        
        Args:
            applicant_data (dict): Applicant features such as 'credit_amount', 'duration_months', etc.
            risk_score (float): The risk score output by the credit model.
            threshold (float): The decision threshold used by the model.
            context (str): Economic context (e.g., "bleak", "neutral", "positive").
            decision (bool): Final decision, where a truthy value typically indicates rejection.
        
        Returns:
            dict: A dictionary containing the explanation and metrics.
        """
        start_time = datetime.now()
        
        # Validate inputs
        self._validate_inputs(applicant_data, risk_score, threshold, context, decision)
        
        # Check cache
        cache_key = self._get_cache_key(applicant_data, risk_score, threshold, context, decision)
        cached_response = self._get_cached_response(cache_key)
        if cached_response:
            return {
                'explanation': cached_response,
                'metrics': ExplanationMetrics(
                    generation_time=0.0,
                    explanation_length=len(cached_response),
                    confidence_score=1.0
                )
            }
        
        # If LLM-based explanation is disabled, use the rule-based approach
        if not self.use_llm:
            explanation = self.generate_rule_based_explanation(risk_score, threshold, context, decision)
            metrics = ExplanationMetrics(
                generation_time=(datetime.now() - start_time).total_seconds(),
                explanation_length=len(explanation),
                confidence_score=1.0
            )
            return {'explanation': explanation, 'metrics': metrics}
        
        try:
            # Extract key applicant features
            key_features = {
                'credit_amount': applicant_data.get('credit_amount', 'Unknown'),
                'duration_months': applicant_data.get('duration_months', 'Unknown'),
                'purpose': applicant_data.get('purpose', 'Unknown'),
                'credit_history': applicant_data.get('credit_history', 'Unknown'),
                'savings_account': applicant_data.get('savings_account', 'Unknown'),
                'employment_since': applicant_data.get('employment_since', 'Unknown')
            }
            
            # Calculate feature importance
            feature_importance = self._calculate_feature_importance(applicant_data)
            
            # Construct enhanced prompt with academic insights
            prompt = f"""
            You are an expert credit decision explainer. Your task is to provide a clear, fair, and transparent explanation for a credit decision.

            Applicant Information:
            - Loan amount: {key_features['credit_amount']}
            - Duration: {key_features['duration_months']} months
            - Purpose: {key_features['purpose']}
            - Credit history: {key_features['credit_history']}
            - Savings account: {key_features['savings_account']}
            - Employment status: {key_features['employment_since']}

            Decision Details:
            - Risk score: {risk_score:.2f} (higher indicates higher risk)
            - Decision threshold: {threshold:.2f}
            - Economic context: {context}
            - Final Decision: {"REJECTED" if decision else "APPROVED"}

            Feature Importance:
            {json.dumps(feature_importance, indent=2)}

            Academic Insights:
            Based on the findings in "LLMs for Explainable AI: A Comprehensive Survey" (Bilal et al., 2025),
            please ensure the explanation integrates post-hoc analysis, intrinsic interpretability, and 
            human-centered narrative approaches. Emphasize clarity, factual accuracy, and logical coherence.
            Evaluate the explanation along dimensions of comprehensibility, faithfulness, and plausibility.

            Please provide a 3-4 sentence explanation that:
            1. Clearly states the decision.
            2. Explains the key factors influencing the decision.
            3. Provides context about the economic conditions.
            4. Offers constructive feedback for future applications.
            5. Emphasizes fairness, transparency, and academic rigor.

            Format the explanation in a professional, empathetic tone.
            """
            
            # Generate explanation using LLM
            response = self.client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt.strip()}],
                temperature=0.7,
                max_tokens=300
            )
            
            explanation = response.choices[0].message.content.strip()
            
            # Cache the response
            self._response_cache[cache_key] = (explanation, datetime.now())
            
            # Calculate metrics
            metrics = ExplanationMetrics(
                generation_time=(datetime.now() - start_time).total_seconds(),
                explanation_length=len(explanation),
                confidence_score=1.0 if response.choices[0].finish_reason == "stop" else 0.0,
                feature_importance=feature_importance
            )
            
            return {'explanation': explanation, 'metrics': metrics}
            
        except Exception as e:
            print(f"❌ LLM explanation failed: {e}")
            explanation = self.generate_rule_based_explanation(risk_score, threshold, context, decision)
            metrics = ExplanationMetrics(
                generation_time=(datetime.now() - start_time).total_seconds(),
                explanation_length=len(explanation),
                confidence_score=1.0
            )
            return {'explanation': explanation, 'metrics': metrics}
    
    def generate_rule_based_explanation(self, risk_score: float, threshold: float, 
                                        context: str, decision: bool) -> str:
        """
        Generate a rule-based explanation when LLM is unavailable.
        
        Args:
            risk_score (float): The applicant's risk score.
            threshold (float): The decision threshold.
            context (str): Economic context, which may alter the tone of the explanation.
            decision (bool): The final decision; truthy values indicate rejection.
            
        Returns:
            str: A rule-based explanation.
        """
        decision_text = "approved" if not decision else "declined"
        
        context_phrases = {
            "bleak": "During the current economic downturn, we've adjusted our lending criteria to be more conservative.",
            "neutral": "Based on current economic conditions, we're using standard lending criteria.",
            "positive": "In the current favorable economic climate, we are able to offer competitive lending terms."
        }
        
        context_phrase = context_phrases.get(context, "Based on current economic conditions,")
        
        if decision:  # Rejected case
            if risk_score > threshold + 0.1:
                explanation = (
                    f"Your application has been {decision_text}. {context_phrase} "
                    f"Your risk score of {risk_score:.2f} was significantly above our threshold of {threshold:.2f}, "
                    "indicating a level of risk that exceeds our acceptable limits. "
                    "We encourage you to review your credit profile and consider reapplying in the future."
                )
            else:
                explanation = (
                    f"Your application has been {decision_text}. {context_phrase} "
                    f"Your risk score of {risk_score:.2f} was slightly above our threshold of {threshold:.2f}. "
                    "We recommend strengthening your credit profile and reapplying in the future. "
                    "Consider improving your credit score or providing additional collateral."
                )
        else:  # Approved case
            if risk_score < threshold - 0.1:
                explanation = (
                    f"Your application has been {decision_text}! {context_phrase} "
                    f"Your risk score of {risk_score:.2f} was well below our threshold of {threshold:.2f}, "
                    "reflecting a robust credit profile. We are pleased to offer you competitive terms."
                )
            else:
                explanation = (
                    f"Your application has been {decision_text}. {context_phrase} "
                    f"Your risk score of {risk_score:.2f} was just below our threshold of {threshold:.2f}. "
                    "We are able to offer you standard terms based on your credit profile."
                )
                
        return explanation
